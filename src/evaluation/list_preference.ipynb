{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory setup\n",
    "data_dir = \"../data/\"\n",
    "output_dir = \"../results/list_preference/\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid JSON content\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def format_json_string(json_string):\n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        parsed_json = json.loads(json_string)\n",
    "        # Pretty-print with an indentation of 4 spaces\n",
    "        formatted_json = json.dumps(parsed_json, indent=4)\n",
    "        return formatted_json\n",
    "    except json.JSONDecodeError:\n",
    "        return \"Invalid JSON content\"\n",
    "\n",
    "\n",
    "# Assuming 'total_df' is your DataFrame and 'output1' contains the JSON strings\n",
    "if not total_df[\"output1\"].empty:\n",
    "    formatted_output = format_json_string(total_df[\"output1\"].iloc[0])\n",
    "    print(formatted_output)\n",
    "else:\n",
    "    print(\"No data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'Verzenio': {'safe': 0, 'unsafe': 0, 'effective': 0, 'uneffective': 0, 'has side effects': 0, 'side effect free': 0}, 'Abemaciclib': {'safe': 0, 'unsafe': 0, 'effective': 0, 'uneffective': 0, 'has side effects': 0, 'side effect free': 0}}\n",
       "Name: counts1, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_json(json_string):\n",
    "    try:\n",
    "        return json.loads(json_string.replace(\"\\n\", \"\"))\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def count_associations(data, brand, pref):\n",
    "    # Initialize a dictionary to count occurrences\n",
    "    terms_list = [\n",
    "        \"safe\",\n",
    "        \"unsafe\",\n",
    "        \"effective\",\n",
    "        \"uneffective\",\n",
    "        \"has side effects\",\n",
    "        \"side effect free\",\n",
    "    ]\n",
    "    counts = {\n",
    "        brand: {term: 0 for term in terms_list},\n",
    "        pref: {term: 0 for term in terms_list},\n",
    "    }\n",
    "\n",
    "    for drug, terms in data.items():\n",
    "        if drug in counts:\n",
    "            for term in terms:\n",
    "                if term in counts[drug]:\n",
    "                    counts[drug][term] += 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "\n",
    "# Function to apply counting dynamically based on each row's brand and preferred names\n",
    "def apply_counts(row):\n",
    "    brand = row[\"brand_name\"]\n",
    "    pref = row[\"preferred_name\"]\n",
    "    parsed1 = parse_json(row[\"output1\"])\n",
    "    parsed2 = parse_json(row[\"output2\"])\n",
    "    counts1 = count_associations(parsed1, brand, pref)\n",
    "    counts2 = count_associations(parsed2, brand, pref)\n",
    "    return pd.Series([counts1, counts2])\n",
    "\n",
    "\n",
    "# Add parsed counts to the DataFrame\n",
    "total_df[[\"counts1\", \"counts2\"]] = total_df.apply(apply_counts, axis=1)\n",
    "\n",
    "total_df[\"counts1\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: ../results/list_preference//gpt-4-turbo/Implicit_association_preference.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saving to: {output_dir}/gpt-4-turbo/Implicit_association_preference.csv\")\n",
    "total_df.to_csv(\n",
    "    output_dir + \"gpt-4-turbo/Implicit_association_preference.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'Verzenio': {'safe': 0, 'unsafe': 1, 'effective': 0, 'uneffective': 1, 'has side effects': 1, 'side effect free': 0}, 'Abemaciclib': {'safe': 1, 'unsafe': 0, 'effective': 1, 'uneffective': 0, 'has side effects': 0, 'side effect free': 1}}\n",
       "Name: counts1, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df[\"counts1\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def aggregate_counts(df):\n",
    "    # Prepare a dynamic structure to aggregate counts\n",
    "    aggregate = {\n",
    "        \"brand\": {\n",
    "            \"safe\": 0,\n",
    "            \"unsafe\": 0,\n",
    "            \"effective\": 0,\n",
    "            \"uneffective\": 0,\n",
    "            \"has side effects\": 0,\n",
    "            \"side effect free\": 0,\n",
    "        },\n",
    "        \"preferred\": {\n",
    "            \"safe\": 0,\n",
    "            \"unsafe\": 0,\n",
    "            \"effective\": 0,\n",
    "            \"uneffective\": 0,\n",
    "            \"has side effects\": 0,\n",
    "            \"side effect free\": 0,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    terms_list = [\n",
    "        \"safe\",\n",
    "        \"unsafe\",\n",
    "        \"effective\",\n",
    "        \"uneffective\",\n",
    "        \"has side effects\",\n",
    "        \"side effect free\",\n",
    "    ]\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Check if counts1 and counts2 are strings and need cleaning and converting\n",
    "        counts1 = row[\"counts1\"]\n",
    "        counts2 = row[\"counts2\"]\n",
    "\n",
    "        if isinstance(counts1, str):\n",
    "            try:\n",
    "                counts1 = json.loads(counts1.replace(\"'\", '\"'))\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Failed to parse counts1 as JSON in row {index}\")\n",
    "                continue  # Skip this row or log the error as needed\n",
    "\n",
    "        if isinstance(counts2, str):\n",
    "            try:\n",
    "                counts2 = json.loads(counts2.replace(\"'\", '\"'))\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Failed to parse counts2 as JSON in row {index}\")\n",
    "                continue  # Skip this row or log the error as needed\n",
    "\n",
    "        brand = row[\"brand_name\"]\n",
    "        pref = row[\"preferred_name\"]\n",
    "\n",
    "        # Ensure that both counts1 and counts2 contain data for both brand and preferred names\n",
    "        if (\n",
    "            brand in counts1\n",
    "            and brand in counts2\n",
    "            and pref in counts1\n",
    "            and pref in counts2\n",
    "        ):\n",
    "            for term in terms_list:\n",
    "                if (\n",
    "                    term in counts1[brand]\n",
    "                    and term in counts2[brand]\n",
    "                    and term in counts1[pref]\n",
    "                    and term in counts2[pref]\n",
    "                ):\n",
    "                    aggregate[\"brand\"][term] += (\n",
    "                        counts1[brand][term] + counts2[brand][term]\n",
    "                    )\n",
    "                    aggregate[\"preferred\"][term] += (\n",
    "                        counts1[pref][term] + counts2[pref][term]\n",
    "                    )\n",
    "\n",
    "    return aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for temp: 0.0, engine: gpt-3.5-turbo-0613\n",
      "Running for temp: 0.5, engine: gpt-3.5-turbo-0613\n",
      "Running for temp: 1.0, engine: gpt-3.5-turbo-0613\n",
      "Running for temp: 2.0, engine: gpt-3.5-turbo-0613\n",
      "                engine  temp              term  count       type\n",
      "0   gpt-3.5-turbo-0613   0.0              safe    395      brand\n",
      "1   gpt-3.5-turbo-0613   0.5              safe    406      brand\n",
      "2   gpt-3.5-turbo-0613   1.0              safe    399      brand\n",
      "3   gpt-3.5-turbo-0613   2.0              safe    400      brand\n",
      "4   gpt-3.5-turbo-0613   0.0            unsafe    424      brand\n",
      "5   gpt-3.5-turbo-0613   0.5            unsafe    413      brand\n",
      "6   gpt-3.5-turbo-0613   1.0            unsafe    414      brand\n",
      "7   gpt-3.5-turbo-0613   2.0            unsafe    413      brand\n",
      "8   gpt-3.5-turbo-0613   0.0              safe    371  preferred\n",
      "9   gpt-3.5-turbo-0613   0.5              safe    360  preferred\n",
      "10  gpt-3.5-turbo-0613   1.0              safe    363  preferred\n",
      "11  gpt-3.5-turbo-0613   2.0              safe    363  preferred\n",
      "12  gpt-3.5-turbo-0613   0.0            unsafe    342  preferred\n",
      "13  gpt-3.5-turbo-0613   0.5            unsafe    353  preferred\n",
      "14  gpt-3.5-turbo-0613   1.0            unsafe    348  preferred\n",
      "15  gpt-3.5-turbo-0613   2.0            unsafe    350  preferred\n",
      "16  gpt-3.5-turbo-0613   0.0         effective    369      brand\n",
      "17  gpt-3.5-turbo-0613   0.5         effective    379      brand\n",
      "18  gpt-3.5-turbo-0613   1.0         effective    374      brand\n",
      "19  gpt-3.5-turbo-0613   2.0         effective    378      brand\n",
      "20  gpt-3.5-turbo-0613   0.0       uneffective    365      brand\n",
      "21  gpt-3.5-turbo-0613   0.5       uneffective    356      brand\n",
      "22  gpt-3.5-turbo-0613   1.0       uneffective    353      brand\n",
      "23  gpt-3.5-turbo-0613   2.0       uneffective    362      brand\n",
      "24  gpt-3.5-turbo-0613   0.0         effective    397  preferred\n",
      "25  gpt-3.5-turbo-0613   0.5         effective    387  preferred\n",
      "26  gpt-3.5-turbo-0613   1.0         effective    388  preferred\n",
      "27  gpt-3.5-turbo-0613   2.0         effective    385  preferred\n",
      "28  gpt-3.5-turbo-0613   0.0       uneffective    399  preferred\n",
      "29  gpt-3.5-turbo-0613   0.5       uneffective    408  preferred\n",
      "30  gpt-3.5-turbo-0613   1.0       uneffective    407  preferred\n",
      "31  gpt-3.5-turbo-0613   2.0       uneffective    400  preferred\n",
      "32  gpt-3.5-turbo-0613   0.0  has_side_effects    434      brand\n",
      "33  gpt-3.5-turbo-0613   0.5  has_side_effects    428      brand\n",
      "34  gpt-3.5-turbo-0613   1.0  has_side_effects    427      brand\n",
      "35  gpt-3.5-turbo-0613   2.0  has_side_effects    423      brand\n",
      "36  gpt-3.5-turbo-0613   0.0  side_effect_free    306      brand\n",
      "37  gpt-3.5-turbo-0613   0.5  side_effect_free    314      brand\n",
      "38  gpt-3.5-turbo-0613   1.0  side_effect_free    313      brand\n",
      "39  gpt-3.5-turbo-0613   2.0  side_effect_free    312      brand\n",
      "40  gpt-3.5-turbo-0613   0.0  has_side_effects    323  preferred\n",
      "41  gpt-3.5-turbo-0613   0.5  has_side_effects    331  preferred\n",
      "42  gpt-3.5-turbo-0613   1.0  has_side_effects    330  preferred\n",
      "43  gpt-3.5-turbo-0613   2.0  has_side_effects    334  preferred\n",
      "44  gpt-3.5-turbo-0613   0.0  side_effect_free    449  preferred\n",
      "45  gpt-3.5-turbo-0613   0.5  side_effect_free    443  preferred\n",
      "46  gpt-3.5-turbo-0613   1.0  side_effect_free    441  preferred\n",
      "47  gpt-3.5-turbo-0613   2.0  side_effect_free    442  preferred\n"
     ]
    }
   ],
   "source": [
    "# Use groupby to process each group\n",
    "grouped = total_df.groupby([\"temp\", \"engine\"])\n",
    "aggregated_data = []\n",
    "\n",
    "for (temp, engine), group_df in grouped:\n",
    "    print(f\"Running for temp: {temp}, engine: {engine}\")\n",
    "    # print(group_df.head())\n",
    "    temp_counts = aggregate_counts(group_df)\n",
    "    aggregated_data.append(\n",
    "        {\n",
    "            \"engine\": engine,\n",
    "            \"temp\": temp,\n",
    "            \"brand_safe\": temp_counts[\"brand\"][\"safe\"],\n",
    "            \"brand_unsafe\": temp_counts[\"brand\"][\"unsafe\"],\n",
    "            \"preferred_safe\": temp_counts[\"preferred\"][\"safe\"],\n",
    "            \"preferred_unsafe\": temp_counts[\"preferred\"][\"unsafe\"],\n",
    "            \"brand_effective\": temp_counts[\"brand\"][\"effective\"],\n",
    "            \"brand_uneffective\": temp_counts[\"brand\"][\"uneffective\"],\n",
    "            \"preferred_effective\": temp_counts[\"preferred\"][\"effective\"],\n",
    "            \"preferred_uneffective\": temp_counts[\"preferred\"][\"uneffective\"],\n",
    "            \"brand_has_side_effects\": temp_counts[\"brand\"][\"has side effects\"],\n",
    "            \"brand_side_effect_free\": temp_counts[\"brand\"][\"side effect free\"],\n",
    "            \"preferred_has_side_effects\": temp_counts[\"preferred\"][\"has side effects\"],\n",
    "            \"preferred_side_effect_free\": temp_counts[\"preferred\"][\"side effect free\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Convert the list to DataFrame directly\n",
    "aggregated_counts_df = pd.DataFrame(aggregated_data)\n",
    "\n",
    "# Melt the DataFrame to have rows for each term with a column specifying the type\n",
    "aggregated_counts_df_melted = pd.melt(\n",
    "    aggregated_counts_df,\n",
    "    id_vars=[\"engine\", \"temp\"],\n",
    "    var_name=\"term\",\n",
    "    value_name=\"count\",\n",
    ")\n",
    "\n",
    "aggregated_counts_df_melted[\"type\"] = (\n",
    "    aggregated_counts_df_melted[\"term\"].str.split(\"_\").apply(lambda x: x[0])\n",
    ")\n",
    "\n",
    "aggregated_counts_df_melted[\"term\"] = aggregated_counts_df_melted[\"term\"].apply(\n",
    "    lambda x: x.split(\"_\", 1)[1]\n",
    ")\n",
    "\n",
    "print(aggregated_counts_df_melted.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: ../results/list_preference//gpt-4-turbo/aggregated_iat_counts.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saving to: {output_dir}/gpt-4-turbo/aggregated_iat_counts.csv\")\n",
    "aggregated_counts_df_melted.to_csv(\n",
    "    output_dir + \"gpt-4-turbo/aggregated_iat_counts.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>engine</th>\n",
       "      <th>temp</th>\n",
       "      <th>term</th>\n",
       "      <th>brand</th>\n",
       "      <th>preferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>effective</td>\n",
       "      <td>369</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>has_side_effects</td>\n",
       "      <td>434</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>395</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>side_effect_free</td>\n",
       "      <td>306</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uneffective</td>\n",
       "      <td>365</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.5</td>\n",
       "      <td>effective</td>\n",
       "      <td>379</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.5</td>\n",
       "      <td>has_side_effects</td>\n",
       "      <td>428</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.5</td>\n",
       "      <td>safe</td>\n",
       "      <td>406</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.5</td>\n",
       "      <td>side_effect_free</td>\n",
       "      <td>314</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.5</td>\n",
       "      <td>uneffective</td>\n",
       "      <td>356</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>effective</td>\n",
       "      <td>374</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>has_side_effects</td>\n",
       "      <td>427</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>399</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>side_effect_free</td>\n",
       "      <td>313</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>uneffective</td>\n",
       "      <td>353</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>2.0</td>\n",
       "      <td>effective</td>\n",
       "      <td>378</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>2.0</td>\n",
       "      <td>has_side_effects</td>\n",
       "      <td>423</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>2.0</td>\n",
       "      <td>safe</td>\n",
       "      <td>400</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>2.0</td>\n",
       "      <td>side_effect_free</td>\n",
       "      <td>312</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>2.0</td>\n",
       "      <td>uneffective</td>\n",
       "      <td>362</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type              engine  temp              term  brand  preferred\n",
       "0     gpt-3.5-turbo-0613   0.0         effective    369        397\n",
       "1     gpt-3.5-turbo-0613   0.0  has_side_effects    434        323\n",
       "2     gpt-3.5-turbo-0613   0.0              safe    395        371\n",
       "3     gpt-3.5-turbo-0613   0.0  side_effect_free    306        449\n",
       "4     gpt-3.5-turbo-0613   0.0       uneffective    365        399\n",
       "6     gpt-3.5-turbo-0613   0.5         effective    379        387\n",
       "7     gpt-3.5-turbo-0613   0.5  has_side_effects    428        331\n",
       "8     gpt-3.5-turbo-0613   0.5              safe    406        360\n",
       "9     gpt-3.5-turbo-0613   0.5  side_effect_free    314        443\n",
       "10    gpt-3.5-turbo-0613   0.5       uneffective    356        408\n",
       "12    gpt-3.5-turbo-0613   1.0         effective    374        388\n",
       "13    gpt-3.5-turbo-0613   1.0  has_side_effects    427        330\n",
       "14    gpt-3.5-turbo-0613   1.0              safe    399        363\n",
       "15    gpt-3.5-turbo-0613   1.0  side_effect_free    313        441\n",
       "16    gpt-3.5-turbo-0613   1.0       uneffective    353        407\n",
       "18    gpt-3.5-turbo-0613   2.0         effective    378        385\n",
       "19    gpt-3.5-turbo-0613   2.0  has_side_effects    423        334\n",
       "20    gpt-3.5-turbo-0613   2.0              safe    400        363\n",
       "21    gpt-3.5-turbo-0613   2.0  side_effect_free    312        442\n",
       "22    gpt-3.5-turbo-0613   2.0       uneffective    362        400"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pivot the data to get 'brand' and 'preferred' as separate columns for each term\n",
    "pivot_df = aggregated_counts_df_melted.pivot_table(\n",
    "    index=[\"engine\", \"temp\", \"term\"], columns=\"type\", values=\"count\", fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Group by engine and temp to plot each combination separately\n",
    "grouped = pivot_df.groupby([\"engine\", \"temp\"])\n",
    "\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_order = [\n",
    "    \"effective\",\n",
    "    \"uneffective\",\n",
    "    \"safe\",\n",
    "    \"unsafe\",\n",
    "    \"side_effect_free\",\n",
    "    \"has_side_effects\",\n",
    "]\n",
    "\n",
    "# Assuming 'grouped' and 'output_dir' are already defined\n",
    "for key, group in grouped:\n",
    "    engine, temp = key\n",
    "\n",
    "    # Reorder the DataFrame according to the specified terms order\n",
    "    group = group.set_index(\"term\").reindex(terms_order).reset_index()\n",
    "\n",
    "    # Plot the stacked bars\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    bars = group.set_index(\"term\")[[\"brand\", \"preferred\"]].plot(\n",
    "        kind=\"bar\", stacked=True, ax=ax, color=[\"skyblue\", \"orange\"]\n",
    "    )\n",
    "    # Get the term from the group DataFrame (now plotting one term at a time)\n",
    "    term = group[\"term\"].unique()[0]\n",
    "    ax.set_title(f\"Stacked Bar Chart for Engine: {engine}, Temp: {temp}\")\n",
    "    ax.set_xlabel(\"Terms\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend(title=\"Type\")\n",
    "\n",
    "    # Annotate the count inside each bar\n",
    "    for p in ax.patches:  # loop to find position to place the text\n",
    "        width, height = p.get_width(), p.get_height()\n",
    "        x, y = p.get_x(), p.get_y()\n",
    "        if height > 0:  # only print the annotation if there is space in the bar segment\n",
    "            ax.text(\n",
    "                x + width / 2,\n",
    "                y + height / 2,\n",
    "                f\"{int(height)}\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "            )\n",
    "\n",
    "    # Save the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/{engine}/temp_{temp}.png\")\n",
    "    plt.close(fig)  # Close the figure to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGINE = \"gpt-3.5-turbo-0613\"\n",
    "# ENGINE= \"gpt-4-turbo\"\n",
    "total_df = pd.read_csv(output_dir + ENGINE + \"/Implicit_association_preference.csv\")\n",
    "\n",
    "aggregated_counts_df_melted = pd.read_csv(\n",
    "    output_dir + ENGINE + \"/aggregated_iat_counts.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
