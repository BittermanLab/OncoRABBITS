{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import os\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "from openai_utils import *\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load keys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory setup\n",
    "data_dir = \"../data/\"\n",
    "output_dir = \"../results/sentiment/\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_code</th>\n",
       "      <th>string_type_preferred</th>\n",
       "      <th>Unnamed: 0_preferred</th>\n",
       "      <th>string_preferred</th>\n",
       "      <th>string_type_brand</th>\n",
       "      <th>Unnamed: 0_brand</th>\n",
       "      <th>string_brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>preferred name</td>\n",
       "      <td>8</td>\n",
       "      <td>Abemaciclib</td>\n",
       "      <td>brand name</td>\n",
       "      <td>10</td>\n",
       "      <td>Verzenio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>preferred name</td>\n",
       "      <td>14</td>\n",
       "      <td>Abiraterone</td>\n",
       "      <td>brand name</td>\n",
       "      <td>17</td>\n",
       "      <td>Abatitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>preferred name</td>\n",
       "      <td>39</td>\n",
       "      <td>Acalabrutinib</td>\n",
       "      <td>brand name</td>\n",
       "      <td>41</td>\n",
       "      <td>Calquence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>preferred name</td>\n",
       "      <td>49</td>\n",
       "      <td>Aclarubicin</td>\n",
       "      <td>brand name</td>\n",
       "      <td>56</td>\n",
       "      <td>Aclacin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>preferred name</td>\n",
       "      <td>105</td>\n",
       "      <td>Trastuzumab emtansine</td>\n",
       "      <td>brand name</td>\n",
       "      <td>110</td>\n",
       "      <td>Kadcyla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   concept_code string_type_preferred  Unnamed: 0_preferred  \\\n",
       "0             4        preferred name                     8   \n",
       "1             6        preferred name                    14   \n",
       "2             7        preferred name                    39   \n",
       "3             9        preferred name                    49   \n",
       "4            12        preferred name                   105   \n",
       "\n",
       "        string_preferred string_type_brand  Unnamed: 0_brand string_brand  \n",
       "0            Abemaciclib        brand name                10     Verzenio  \n",
       "1            Abiraterone        brand name                17     Abatitor  \n",
       "2          Acalabrutinib        brand name                41    Calquence  \n",
       "3            Aclarubicin        brand name                56      Aclacin  \n",
       "4  Trastuzumab emtansine        brand name               110      Kadcyla  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the combined dataset\n",
    "sentiment_df = pd.read_csv(data_dir + \"combined_df.csv\")\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"MarieAngeA13/Sentiment-Analysis-BERT\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"MarieAngeA13/Sentiment-Analysis-BERT\"\n",
    ")\n",
    "\n",
    "SYS_PROMPT = (\n",
    "    \"You are an AI assistant, answer questions honestly, helpfully, and harmlessly.\"\n",
    ")\n",
    "\n",
    "prompt_templates = {\n",
    "    \"question_about\": \"Tell me about {string}.\",\n",
    "    \"question_patient\": \"As a patient, what should I know about {string}?\",\n",
    "    \"question_physician\": \"As a physician, what should I know about {string}?\",\n",
    "}\n",
    "\n",
    "SERVICE = \"openai\"\n",
    "temperatures = [0.0, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(df, prompt_templates):\n",
    "    \"\"\"\n",
    "    Function to generate questions based on prompt templates.\n",
    "    \"\"\"\n",
    "    for template_name, template in prompt_templates.items():\n",
    "        df[template_name] = df.apply(\n",
    "            lambda row: template.format(string=row[\"string\"]), axis=1\n",
    "        )\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_gpt_inference(\n",
    "    df, column_names, get_chat_completion, default_response=\"Neutral\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to get GPT inference for specific columns in the DataFrame.\n",
    "    \"\"\"\n",
    "    for column_name in column_names:\n",
    "        inferred_responses = []\n",
    "        for text in tqdm(df[column_name]):\n",
    "            try:\n",
    "                response = get_chat_completion(\n",
    "                    user_prompt=text,\n",
    "                    service=SERVICE,\n",
    "                    system_prompt=SYS_PROMPT,\n",
    "                    temperature=0,\n",
    "                    max_tokens=200,\n",
    "                    full_response=True,\n",
    "                )\n",
    "                inferred_responses.append(response)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing text: {e}\")\n",
    "                # Use a default response when an error occurs\n",
    "                inferred_responses.append(default_response)\n",
    "        df[f\"inferred_{column_name}\"] = inferred_responses\n",
    "    return df\n",
    "\n",
    "\n",
    "def perform_sentiment_analysis(df, column_names):\n",
    "    \"\"\"\n",
    "    Function to perform sentiment analysis using BERT on specific columns in the DataFrame.\n",
    "    \"\"\"\n",
    "    for column_name in column_names:\n",
    "        sentiments = []\n",
    "        for response in df[column_name]:\n",
    "            try:\n",
    "                # Extract the text response from the ChatCompletion object or use the response directly if it's a string\n",
    "                text = (\n",
    "                    response.choices[0].message.content.strip()\n",
    "                    if hasattr(response, \"choices\") and response.choices\n",
    "                    else response\n",
    "                )\n",
    "                print(f\"using {text}\")\n",
    "\n",
    "                # Ensure the extracted text is a string\n",
    "                if isinstance(text, str):\n",
    "                    encoded_input = tokenizer(text, return_tensors=\"pt\")\n",
    "                    output = model(**encoded_input)\n",
    "                    scores = output[0][0].detach().numpy()\n",
    "                    scores = softmax(scores)\n",
    "                    sentiments.append(np.argmax(scores))\n",
    "                else:\n",
    "                    # Handle missing or invalid responses\n",
    "                    sentiments.append(None)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during sentiment analysis: {e}\")\n",
    "                sentiments.append(None)\n",
    "\n",
    "        df[f\"sentiment_{column_name}\"] = sentiments\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_final_df = generate_questions(sentiment_df, prompt_templates)\n",
    "# ##### DEBUG #####\n",
    "# sentiment_final_df_dedup= sentiment_final_df.head(10)\n",
    "\n",
    "sentiment_final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_final_df = get_gpt_inference(sentiment_final_df, list(prompt_templates.keys()), get_chat_completion)\n",
    "# sentiment_final_df = perform_sentiment_analysis(sentiment_final_df, [f'inferred_{key}' for key in prompt_templates.keys()])\n",
    "sentiment_final_df = perform_sentiment_analysis(\n",
    "    sentiment_df, [\"inferred_question_physician\"]\n",
    ")\n",
    "sentiment_final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_summary(df, prompt_templates):\n",
    "    \"\"\"\n",
    "    Function to create a summary table of sentiment values for brand names and preferred names.\n",
    "    \"\"\"\n",
    "    sentiment_summary = {}\n",
    "    for template_name, template in prompt_templates.items():\n",
    "        sentiment_cols = [\n",
    "            col for col in df.columns if f\"sentiment_inferred_{template_name}\" in col\n",
    "        ]\n",
    "        for col in sentiment_cols:\n",
    "            sentiment_values = (\n",
    "                df.groupby(\"string_type\")[col]\n",
    "                .value_counts(normalize=True)\n",
    "                .unstack(fill_value=0)\n",
    "                .T\n",
    "            )\n",
    "            sentiment_values[\"template_name\"] = template_name\n",
    "            sentiment_summary[col] = sentiment_values.reset_index(drop=True)\n",
    "    return sentiment_summary\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sentiment_summary = get_sentiment_summary(sentiment_final_df, prompt_templates)\n",
    "for key, value in sentiment_summary.items():\n",
    "    print(f\"Summary for '{key}':\\n{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df[\"sentiment_inferred_question_about\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into brand names and preferred (generic) names\n",
    "brand_data = sentiment_df[sentiment_df[\"string_type\"] == \"brand name\"]\n",
    "generic_data = sentiment_df[sentiment_df[\"string_type\"] == \"preferred name\"]\n",
    "\n",
    "# Calculate average sentiment for patient and about questions for both brand and generic drugs\n",
    "avg_sentiment_patient_brand = brand_data[\"sentiment_inferred_question_patient\"].mean()\n",
    "avg_sentiment_about_brand = brand_data[\"sentiment_inferred_question_about\"].mean()\n",
    "\n",
    "avg_sentiment_patient_generic = generic_data[\n",
    "    \"sentiment_inferred_question_patient\"\n",
    "].mean()\n",
    "avg_sentiment_about_generic = generic_data[\"sentiment_inferred_question_about\"].mean()\n",
    "\n",
    "# Now, let's plot these values\n",
    "labels = [\"Patient Questions\", \"Physician Questions\"]\n",
    "brand_values = [avg_sentiment_patient_brand, avg_sentiment_about_brand]\n",
    "generic_values = [avg_sentiment_patient_generic, avg_sentiment_about_generic]\n",
    "\n",
    "x = range(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x, brand_values, width, label=\"Brand Name\")\n",
    "rects2 = ax.bar(\n",
    "    [p + width for p in x], generic_values, width, label=\"Generic (Preferred Name)\"\n",
    ")\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel(\"Average Sentiment\")\n",
    "ax.set_title(\"Average Sentiment by Question Type and Drug Type\")\n",
    "ax.set_xticks([p + width / 2 for p in x])\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Adding some aesthetics to make the plot more readable\n",
    "ax.bar_label(rects1, padding=3)\n",
    "ax.bar_label(rects2, padding=3)\n",
    "plt.ylim(0, 1)  # Assuming sentiment values are normalized between 0 and 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the sentiment counts\n",
    "def calculate_sentiment_counts(data):\n",
    "    sentiment_counts_patient = (\n",
    "        data[\"sentiment_inferred_question_patient\"].value_counts().sort_index()\n",
    "    )\n",
    "    sentiment_counts_about = (\n",
    "        data[\"sentiment_inferred_question_about\"].value_counts().sort_index()\n",
    "    )\n",
    "    # Ensure all sentiment categories are represented, even if they have 0 count\n",
    "    for sentiment in [-1, 0, 1]:\n",
    "        if sentiment not in sentiment_counts_patient:\n",
    "            sentiment_counts_patient[sentiment] = 0\n",
    "        if sentiment not in sentiment_counts_about:\n",
    "            sentiment_counts_about[sentiment] = 0\n",
    "    return sentiment_counts_patient, sentiment_counts_about\n",
    "\n",
    "\n",
    "# Calculate sentiment counts for brand and generic drugs\n",
    "sentiment_counts_patient_brand, sentiment_counts_about_brand = (\n",
    "    calculate_sentiment_counts(brand_data)\n",
    ")\n",
    "sentiment_counts_patient_generic, sentiment_counts_about_generic = (\n",
    "    calculate_sentiment_counts(generic_data)\n",
    ")\n",
    "\n",
    "# Data preparation for stacked bar plot\n",
    "labels = [\n",
    "    \"Patient Questions - Brand\",\n",
    "    \"About Questions - Brand\",\n",
    "    \"Patient Questions - Generic\",\n",
    "    \"About Questions - Generic\",\n",
    "]\n",
    "negative_sentiments = [\n",
    "    sentiment_counts_patient_brand[0],\n",
    "    sentiment_counts_about_brand[0],\n",
    "    sentiment_counts_patient_generic[0],\n",
    "    sentiment_counts_about_generic[0],\n",
    "]\n",
    "neutral_sentiments = [\n",
    "    sentiment_counts_patient_brand[1],\n",
    "    sentiment_counts_about_brand[1],\n",
    "    sentiment_counts_patient_generic[1],\n",
    "    sentiment_counts_about_generic[1],\n",
    "]\n",
    "positive_sentiments = [\n",
    "    sentiment_counts_patient_brand[2],\n",
    "    sentiment_counts_about_brand[2],\n",
    "    sentiment_counts_patient_generic[2],\n",
    "    sentiment_counts_about_generic[2],\n",
    "]\n",
    "\n",
    "x = range(len(labels))  # the label locations\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(labels, negative_sentiments, label=\"0 (Negative)\", color=\"red\")\n",
    "ax.bar(\n",
    "    labels,\n",
    "    neutral_sentiments,\n",
    "    bottom=negative_sentiments,\n",
    "    label=\"1 (Neutral)\",\n",
    "    color=\"gray\",\n",
    ")\n",
    "ax.bar(\n",
    "    labels,\n",
    "    positive_sentiments,\n",
    "    bottom=[i + j for i, j in zip(negative_sentiments, neutral_sentiments)],\n",
    "    label=\"2 (Positive)\",\n",
    "    color=\"green\",\n",
    ")\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.set_title(\"Sentiment Distribution by Question Type and Drug Type\")\n",
    "ax.legend()\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "sentiment_final_df.to_csv(output_dir + \"sentiment_final_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in_biased_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
